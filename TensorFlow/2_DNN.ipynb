{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_model import FeedForward_DNN, correlation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "import os\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import time\n",
    "import collections\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='Mode'\n",
    "if folder=='Mode':\n",
    "    data_varlist=['BUS_HIGH','BIKE_HIGH','CAR_HIGH','RIDESHARE_NEW']\n",
    "    name_corelist=['Bus','Bike','Car','Rideshare']\n",
    "\n",
    "    Z_var_list=['HH_RACE_MINORITY','FEMALE','POVERTY','MEDCOND_NEW', 'RURAL']\n",
    "    Z_note_list=['Race','Female','Poverty','Medcond','Rural']\n",
    "    \n",
    "else:\n",
    "    data_varlist=['PLACE','PRICE','2WRK_HOME_NEW','2WKRMHM_NEW']\n",
    "    name_corelist=['TB','GPI','WFH','WFHO']\n",
    "\n",
    "    Z_var_list=['HH_RACE_MINORITY','R_SEX_IMP_NEW','POVERTY','MEDCOND_NEW', 'URBRUR_NEW']\n",
    "    Z_note_list=['Race','Gender','Poverty','Medcond','Urban']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)\n",
    "\n",
    "FP=False\n",
    "\n",
    "method='cor_soft'#'cor_soft_FP'\n",
    "datatype='Original'\n",
    "num_models = 3\n",
    "n_splits=5\n",
    "\n",
    "layer=3\n",
    "learning_rate=1e-4\n",
    "n_epoch=5000\n",
    "n_mini_batch=500000\n",
    "\n",
    "if layer==3:\n",
    "    model_path ='model_3lyr_'\n",
    "elif layer==0:\n",
    "    model_path ='model_base_'\n",
    "\n",
    "\n",
    "num_alt=2\n",
    "INCLUDE_VAL_SET = False\n",
    "INCLUDE_RAW_SET = False\n",
    "\n",
    "# DIR = 'results/' + folder+'/'+run_name + '/'\n",
    "\n",
    "lam_list=[0]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for k in zip(data_varlist,name_corelist):\n",
    "    run_name =model_path+k[1]#e.g.model_base_Bus\n",
    "    if folder=='Mode':\n",
    "        with open('data/NHTS_balanced/'+k[0]+'_2size_W.pkl', 'rb') as f:\n",
    "            input_data = pickle.load(f)\n",
    "    else:\n",
    "        with open('data/NHTS_unbalanced/NHTS_'+k[0]+'_W.pkl', 'rb') as f:\n",
    "            input_data = pickle.load(f)\n",
    "    X_all_raw=input_data['X_all_raw']\n",
    "    Y_all=input_data['Y_all']\n",
    "    \n",
    "    X_all_raw['FEMALE']=1-X_all_raw['R_SEX_IMP_NEW']\n",
    "    X_all_raw['RURAL']=1-X_all_raw['URBRUR_NEW']\n",
    "    \n",
    "    X_all_raw=X_all_raw.drop(['R_SEX_IMP_NEW','URBRUR_NEW'],axis=1)\n",
    "    \n",
    "    for a in zip(Z_var_list,Z_note_list):\n",
    "        Z_var=a[0]\n",
    "        DIR = 'results/' + folder+'/'+ datatype+'/'+ a[1]+'/'+run_name+'/'\n",
    "        df = []\n",
    "        for e in range(len(lam_list)):\n",
    "            p_dic={}\n",
    "            p_dic['train_accuracy']=[]\n",
    "            p_dic['test_accuracy']=[]\n",
    "            p_dic['train_cm0']=[]\n",
    "            p_dic['train_cm1']=[]\n",
    "            p_dic['test_cm0']=[]\n",
    "            p_dic['test_cm1']=[]\n",
    "            p_dic['train_FNR_gap']=[]\n",
    "            p_dic['test_FNR_gap']=[]\n",
    "            p_dic['train_FPR_gap']=[]\n",
    "            p_dic['test_FPR_gap']=[]\n",
    "\n",
    "            p_dic['TRAINING_PROCESS']={}\n",
    "            p_dic['TRAINING_PROCESS']['best_iter']=[]\n",
    "            p_dic['TRAINING_PROCESS']['final_iter']=[]\n",
    "            p_dic['TRAINING_PROCESS']['accuracy']={}\n",
    "            p_dic['TRAINING_PROCESS']['cost1']={}\n",
    "            p_dic['TRAINING_PROCESS']['cost2']={}\n",
    "            p_dic['TRAINING_PROCESS']['accuracy']['training_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['accuracy']['testing_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost1']['training_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost1']['testing_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost2']['training_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost2']['testing_set']=[]\n",
    "            \n",
    "\n",
    "\n",
    "            for i in range(num_models):\n",
    "                kf = KFold(n_splits, shuffle=True,random_state=0)\n",
    "\n",
    "                #final results\n",
    "                accuracy_train_list = []\n",
    "                accuracy_test_list = []\n",
    "\n",
    "                train_cm0_trial=[]\n",
    "                train_cm1_trial=[]\n",
    "                test_cm0_trial=[]\n",
    "                test_cm1_trial=[]\n",
    "\n",
    "                train_FNR_gap_list=[]\n",
    "                test_FNR_gap_list=[]\n",
    "                train_FPR_gap_list=[]\n",
    "                test_FPR_gap_list=[]\n",
    "\n",
    "                #training process\n",
    "                best_iter_trial=[]\n",
    "                final_iter_trial=[]\n",
    "                accuracy_training_prcoess_trial=[]\n",
    "                accuracy_testing_prcoess_trial=[]\n",
    "                cost1_training_prcoess_trial=[]\n",
    "                cost1_testing_prcoess_trial=[]\n",
    "                cost2_training_prcoess_trial=[]\n",
    "                cost2_testing_prcoess_trial=[]\n",
    "\n",
    "                con=0\n",
    "                for train_idx, test_idx in kf.split(X_all_raw,Y_all):\n",
    "                    con+=1\n",
    "                    MODEL_NAME = 'lambda'+str(lam_list[e])+'_trial' + str(i)+'_fold'+str(con)\n",
    "\n",
    "                    X_train_raw = X_all_raw.iloc[train_idx,:]\n",
    "                    Y_train = Y_all[train_idx]\n",
    "\n",
    "                    X_test_raw = X_all_raw.iloc[test_idx,:]\n",
    "                    Y_test = Y_all[test_idx]\n",
    "                    \n",
    "                    X_train=X_train_raw.loc[:, X_train_raw.columns != 'WTPERFIN']\n",
    "                    X_test=X_test_raw.loc[:, X_test_raw.columns != 'WTPERFIN']\n",
    "                    W_train=X_train_raw['WTPERFIN']\n",
    "                    W_test=X_test_raw['WTPERFIN']\n",
    "                    \n",
    "                    \n",
    "                    N_bootstrap_sample = len(X_train_raw)\n",
    "                    F_DNN = FeedForward_DNN(num_alt,MODEL_NAME,INCLUDE_VAL_SET,INCLUDE_RAW_SET, DIR)\n",
    "                    \n",
    "                    F_DNN.load_data(Z_var)\n",
    "                    F_DNN.init_hyperparameter(lam_list[e],lr=learning_rate,lyr=layer,n_epoch=n_epoch,n_mini_batch=n_mini_batch) # could change the hyperparameter here by using F_DNN.change_hyperparameter(new)\n",
    "                    F_DNN.bootstrap_data(N_bootstrap_sample)\n",
    "                    F_DNN.build_model(method)\n",
    "                    F_DNN.train_model()\n",
    "                    F_DNN.evaluate_model()\n",
    "                     \n",
    "                    print(\" \")\n",
    "                    print('Y:',k[1],'; Z:',a[1],' ',MODEL_NAME,' completed')\n",
    "                    print('accuracy_train: ',F_DNN.accuracy_train,' ;accuracy_test: ',F_DNN.accuracy_test)\n",
    "\n",
    "\n",
    "                    #save results\n",
    "                    accuracy_train_list.append(F_DNN.accuracy_train)\n",
    "                    accuracy_test_list.append(F_DNN.accuracy_test)\n",
    "\n",
    "                    train_cm0=F_DNN.confusion_matrix_z0_train.ravel()\n",
    "                    train_cm1=F_DNN.confusion_matrix_z1_train.ravel()\n",
    "                    train_cm0_trial.append(train_cm0)\n",
    "                    train_cm1_trial.append(train_cm1)\n",
    "\n",
    "                    test_cm0=F_DNN.confusion_matrix_z0_test.ravel()\n",
    "                    test_cm1=F_DNN.confusion_matrix_z1_test.ravel()\n",
    "                    test_cm0_trial.append(test_cm0)\n",
    "                    test_cm1_trial.append(test_cm1)\n",
    "\n",
    "                    train_FNR0=train_cm0[2]/(train_cm0[2]+train_cm0[3])\n",
    "                    train_FNR1=train_cm1[2]/(train_cm1[2]+train_cm1[3])\n",
    "                    train_FNR_gap=train_FNR0-train_FNR1\n",
    "\n",
    "                    test_FNR0=test_cm0[2]/(test_cm0[2]+test_cm0[3])\n",
    "                    test_FNR1=test_cm1[2]/(test_cm1[2]+test_cm1[3])\n",
    "                    test_FNR_gap=test_FNR0-test_FNR1\n",
    "                    \n",
    "                    train_FPR0=train_cm0[1]/(train_cm0[0]+train_cm0[1])\n",
    "                    train_FPR1=train_cm1[1]/(train_cm1[0]+train_cm1[1])\n",
    "                    train_FPR_gap=train_FPR0-train_FPR1\n",
    "\n",
    "                    test_FPR0=test_cm0[1]/(test_cm0[0]+test_cm0[1])\n",
    "                    test_FPR1=test_cm1[1]/(test_cm1[0]+test_cm1[1])\n",
    "                    test_FPR_gap=test_FPR0-test_FPR1\n",
    "\n",
    "                    train_FNR_gap_list.append(train_FNR_gap)\n",
    "                    test_FNR_gap_list.append(test_FNR_gap)\n",
    "                    train_FPR_gap_list.append(train_FPR_gap)\n",
    "                    test_FPR_gap_list.append(test_FPR_gap)\n",
    "                    if not FP:\n",
    "                        print('train_FNR_gap: ',train_FNR_gap,' ;test_FNR_gap: ',test_FNR_gap)\n",
    "                    else:\n",
    "                        print('train_FPR_gap: ',train_FPR_gap,' ;test_FPR_gap: ',test_FPR_gap)\n",
    "                    print('best_iter: ',F_DNN.best_iter)\n",
    "                    time_dur=round(time.time() - start_time, 3)\n",
    "                    print(\"--- %s seconds ---\" % round((time.time() - start_time),4))\n",
    "                    print(\" \")\n",
    "\n",
    "                    #save process\n",
    "                    best_iter_trial.append(F_DNN.best_iter)\n",
    "                    final_iter_trial.append(F_DNN.final_iter)\n",
    "                    accuracy_training_prcoess_trial.append(F_DNN.train_accuracy_list)\n",
    "                    accuracy_testing_prcoess_trial.append(F_DNN.test_accuracy_list)\n",
    "                    cost1_training_prcoess_trial.append(F_DNN.train_cost1_list)\n",
    "                    cost1_testing_prcoess_trial.append(F_DNN.test_cost1_list)\n",
    "                    cost2_training_prcoess_trial.append(F_DNN.train_cost2_list)\n",
    "                    cost2_testing_prcoess_trial.append(F_DNN.test_cost2_list)\n",
    "\n",
    "    #                     print(n_samples)\n",
    "                    df.append([lam_list[e], i,con,F_DNN.h['M'], learning_rate, F_DNN.h['n_mini_batch'],F_DNN.best_iter,F_DNN.final_iter,\\\n",
    "                    F_DNN.accuracy_train, F_DNN.accuracy_test,\\\n",
    "                    train_FNR_gap,test_FNR_gap,train_FPR_gap,test_FPR_gap])\n",
    "\n",
    "\n",
    "                p_dic['train_accuracy'].append(accuracy_train_list)\n",
    "                p_dic['test_accuracy'].append(accuracy_test_list)\n",
    "                p_dic['train_cm0'].append(train_cm0_trial)\n",
    "                p_dic['train_cm1'].append(train_cm1_trial)\n",
    "                p_dic['test_cm0'].append(test_cm0_trial)\n",
    "                p_dic['test_cm1'].append(test_cm1_trial)\n",
    "                p_dic['train_FNR_gap'].append(train_FNR_gap_list)\n",
    "                p_dic['test_FNR_gap'].append(test_FNR_gap_list)\n",
    "                p_dic['train_FPR_gap'].append(train_FPR_gap_list)\n",
    "                p_dic['test_FPR_gap'].append(test_FPR_gap_list)\n",
    "\n",
    "                p_dic['TRAINING_PROCESS']['best_iter'].append(best_iter_trial)\n",
    "                p_dic['TRAINING_PROCESS']['final_iter'].append(final_iter_trial)\n",
    "                p_dic['TRAINING_PROCESS']['accuracy']['training_set'].append(accuracy_training_prcoess_trial)\n",
    "                p_dic['TRAINING_PROCESS']['accuracy']['testing_set'].append(accuracy_testing_prcoess_trial)\n",
    "                p_dic['TRAINING_PROCESS']['cost1']['training_set'].append(cost1_training_prcoess_trial)\n",
    "                p_dic['TRAINING_PROCESS']['cost1']['testing_set'].append(cost1_testing_prcoess_trial)\n",
    "                p_dic['TRAINING_PROCESS']['cost2']['training_set'].append(cost2_training_prcoess_trial)\n",
    "                p_dic['TRAINING_PROCESS']['cost2']['testing_set'].append(cost2_testing_prcoess_trial)\n",
    "\n",
    "                with open('results/' + folder+'/'+ datatype+'/'+ a[1]+'/'+run_name+'.pkl', 'wb') as f:\n",
    "                    pickle.dump(p_dic, f)\n",
    "\n",
    "\n",
    "                df = pd.DataFrame(df, columns = ['lambda','trial','fold','#layers','#lr','batch_size','best_iter','final_iter',\\\n",
    "                                                 'accuracy_train','accuracy_test','FNR_gap_train','FNR_gap_test',\\\n",
    "                                                'FPR_gap_train','FPR_gap_test'])\n",
    "                df.to_csv('results/' + folder+'/'+ datatype+'/'+ a[1]+'/'+run_name+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='Mode'\n",
    "if folder=='Mode':\n",
    "    data_varlist=['RIDESHARE_NEW']\n",
    "    name_corelist=['Rideshare']\n",
    "    \n",
    "    Z_var_list=['RURAL']\n",
    "    Z_note_list=['Rural']\n",
    "    \n",
    "else:\n",
    "    data_varlist=['PLACE']\n",
    "    name_corelist=['TB']\n",
    "\n",
    "    Z_var_list=['HH_RACE_MINORITY']\n",
    "    Z_note_list=['Race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)\n",
    "\n",
    "FP=False\n",
    "\n",
    "if folder=='WFH_Group':\n",
    "    method='cor_soft_FP'\n",
    "else:\n",
    "    method='cor_soft'\n",
    "datatype='Original'\n",
    "num_models = 1\n",
    "n_splits=5\n",
    "\n",
    "layer=0\n",
    "learning_rate=1e-3\n",
    "n_epoch=3000\n",
    "n_mini_batch=500000\n",
    "\n",
    "if layer==3:\n",
    "    model_path ='model_3lyr_'\n",
    "elif layer==0:\n",
    "    model_path ='model_base_'\n",
    "\n",
    "\n",
    "num_alt=2\n",
    "INCLUDE_VAL_SET = False\n",
    "INCLUDE_RAW_SET = False\n",
    "\n",
    "# DIR = 'results/' + folder+'/'+run_name + '/'\n",
    "\n",
    "lam_list=[0.2,0.4,0.6,0.8]\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "    \n",
    "for k in zip(data_varlist,name_corelist):\n",
    "    run_name =model_path+k[1]#e.g.model_base_Bus\n",
    "    if folder=='Mode':\n",
    "        with open('data/NHTS_balanced/'+k[0]+'_2size_W.pkl', 'rb') as f:\n",
    "            input_data = pickle.load(f)\n",
    "    else:\n",
    "        with open('data/NHTS_unbalanced/NHTS_'+k[0]+'_W.pkl', 'rb') as f:\n",
    "            input_data = pickle.load(f)\n",
    "    X_all_raw=input_data['X_all_raw']\n",
    "    Y_all=input_data['Y_all']\n",
    "    \n",
    "    X_all_raw['FEMALE']=1-X_all_raw['R_SEX_IMP_NEW']\n",
    "    X_all_raw['RURAL']=1-X_all_raw['URBRUR_NEW']\n",
    "    \n",
    "    X_all_raw=X_all_raw.drop(['R_SEX_IMP_NEW','URBRUR_NEW'],axis=1)\n",
    "    \n",
    "    for a in zip(Z_var_list,Z_note_list):\n",
    "        Z_var=a[0]\n",
    "        DIR = 'results/' + folder+'/'+ datatype+'/'+ a[1]+'/'+run_name+'/'\n",
    "        df = []\n",
    "        for e in range(len(lam_list)):\n",
    "            p_dic={}\n",
    "            p_dic['train_accuracy']=[]\n",
    "            p_dic['test_accuracy']=[]\n",
    "            p_dic['train_cm0']=[]\n",
    "            p_dic['train_cm1']=[]\n",
    "            p_dic['test_cm0']=[]\n",
    "            p_dic['test_cm1']=[]\n",
    "            p_dic['train_FNR_gap']=[]\n",
    "            p_dic['test_FNR_gap']=[]\n",
    "            p_dic['train_FPR_gap']=[]\n",
    "            p_dic['test_FPR_gap']=[]\n",
    "\n",
    "            p_dic['TRAINING_PROCESS']={}\n",
    "            p_dic['TRAINING_PROCESS']['best_iter']=[]\n",
    "            p_dic['TRAINING_PROCESS']['final_iter']=[]\n",
    "            p_dic['TRAINING_PROCESS']['accuracy']={}\n",
    "            p_dic['TRAINING_PROCESS']['cost1']={}\n",
    "            p_dic['TRAINING_PROCESS']['cost2']={}\n",
    "            p_dic['TRAINING_PROCESS']['accuracy']['training_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['accuracy']['testing_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost1']['training_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost1']['testing_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost2']['training_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost2']['testing_set']=[]\n",
    "            \n",
    "\n",
    "\n",
    "            for i in range(num_models):\n",
    "                kf = KFold(n_splits, shuffle=True,random_state=0)\n",
    "\n",
    "                #final results\n",
    "                accuracy_train_list = []\n",
    "                accuracy_test_list = []\n",
    "\n",
    "                train_cm0_trial=[]\n",
    "                train_cm1_trial=[]\n",
    "                test_cm0_trial=[]\n",
    "                test_cm1_trial=[]\n",
    "\n",
    "                train_FNR_gap_list=[]\n",
    "                test_FNR_gap_list=[]\n",
    "                train_FPR_gap_list=[]\n",
    "                test_FPR_gap_list=[]\n",
    "\n",
    "                #training process\n",
    "                best_iter_trial=[]\n",
    "                final_iter_trial=[]\n",
    "                accuracy_training_prcoess_trial=[]\n",
    "                accuracy_testing_prcoess_trial=[]\n",
    "                cost1_training_prcoess_trial=[]\n",
    "                cost1_testing_prcoess_trial=[]\n",
    "                cost2_training_prcoess_trial=[]\n",
    "                cost2_testing_prcoess_trial=[]\n",
    "\n",
    "                con=0\n",
    "                for train_idx, test_idx in kf.split(X_all_raw,Y_all):\n",
    "                    con+=1\n",
    "                    MODEL_NAME = 'lambda'+str(lam_list[e])+'_trial' + str(i)+'_fold'+str(con)\n",
    "\n",
    "                    X_train_raw = X_all_raw.iloc[train_idx,:]\n",
    "                    Y_train = Y_all[train_idx]\n",
    "\n",
    "                    X_test_raw = X_all_raw.iloc[test_idx,:]\n",
    "                    Y_test = Y_all[test_idx]\n",
    "                    \n",
    "                    X_train=X_train_raw.loc[:, X_train_raw.columns != 'WTPERFIN']\n",
    "                    X_test=X_test_raw.loc[:, X_test_raw.columns != 'WTPERFIN']\n",
    "                    W_train=X_train_raw['WTPERFIN']\n",
    "                    W_test=X_test_raw['WTPERFIN']\n",
    "                    \n",
    "                    \n",
    "                    N_bootstrap_sample = len(X_train_raw)\n",
    "                    F_DNN = FeedForward_DNN(num_alt,MODEL_NAME,INCLUDE_VAL_SET,INCLUDE_RAW_SET, DIR)\n",
    "                    \n",
    "                    F_DNN.load_data(Z_var)\n",
    "                    F_DNN.init_hyperparameter(lam_list[e],lr=learning_rate,lyr=layer,n_epoch=n_epoch,n_mini_batch=n_mini_batch) # could change the hyperparameter here by using F_DNN.change_hyperparameter(new)\n",
    "                    F_DNN.bootstrap_data(N_bootstrap_sample)\n",
    "                    F_DNN.build_model(method)\n",
    "                    F_DNN.train_model()\n",
    "                    F_DNN.evaluate_model()\n",
    "                     \n",
    "                    print(\" \")\n",
    "                    print('Y:',k[1],'; Z:',a[1],' ',MODEL_NAME,' completed')\n",
    "                    print('accuracy_train: ',F_DNN.accuracy_train,' ;accuracy_test: ',F_DNN.accuracy_test)\n",
    "\n",
    "\n",
    "                    #save results\n",
    "                    accuracy_train_list.append(F_DNN.accuracy_train)\n",
    "                    accuracy_test_list.append(F_DNN.accuracy_test)\n",
    "\n",
    "                    train_cm0=F_DNN.confusion_matrix_z0_train.ravel()\n",
    "                    train_cm1=F_DNN.confusion_matrix_z1_train.ravel()\n",
    "                    train_cm0_trial.append(train_cm0)\n",
    "                    train_cm1_trial.append(train_cm1)\n",
    "\n",
    "                    test_cm0=F_DNN.confusion_matrix_z0_test.ravel()\n",
    "                    test_cm1=F_DNN.confusion_matrix_z1_test.ravel()\n",
    "                    test_cm0_trial.append(test_cm0)\n",
    "                    test_cm1_trial.append(test_cm1)\n",
    "\n",
    "                    train_FNR0=train_cm0[2]/(train_cm0[2]+train_cm0[3])\n",
    "                    train_FNR1=train_cm1[2]/(train_cm1[2]+train_cm1[3])\n",
    "                    train_FNR_gap=train_FNR0-train_FNR1\n",
    "\n",
    "                    test_FNR0=test_cm0[2]/(test_cm0[2]+test_cm0[3])\n",
    "                    test_FNR1=test_cm1[2]/(test_cm1[2]+test_cm1[3])\n",
    "                    test_FNR_gap=test_FNR0-test_FNR1\n",
    "                    \n",
    "                    train_FPR0=train_cm0[1]/(train_cm0[0]+train_cm0[1])\n",
    "                    train_FPR1=train_cm1[1]/(train_cm1[0]+train_cm1[1])\n",
    "                    train_FPR_gap=train_FPR0-train_FPR1\n",
    "\n",
    "                    test_FPR0=test_cm0[1]/(test_cm0[0]+test_cm0[1])\n",
    "                    test_FPR1=test_cm1[1]/(test_cm1[0]+test_cm1[1])\n",
    "                    test_FPR_gap=test_FPR0-test_FPR1\n",
    "\n",
    "                    train_FNR_gap_list.append(train_FNR_gap)\n",
    "                    test_FNR_gap_list.append(test_FNR_gap)\n",
    "                    train_FPR_gap_list.append(train_FPR_gap)\n",
    "                    test_FPR_gap_list.append(test_FPR_gap)\n",
    "\n",
    "                    print('train_FNR_gap: ',train_FNR_gap,' ;test_FNR_gap: ',test_FNR_gap)\n",
    "                    print('train_FPR_gap: ',train_FPR_gap,' ;test_FPR_gap: ',test_FPR_gap)\n",
    "                    if con>1:\n",
    "                        print('best_iter: ',F_DNN.best_iter)\n",
    "                    time_dur=round(time.time() - start_time, 3)\n",
    "                    print(\"--- %s seconds ---\" % round((time.time() - start_time),4))\n",
    "                    print(\" \")\n",
    "\n",
    "                    #save process\n",
    "                    \n",
    "                    best_iter_trial.append(F_DNN.best_iter)\n",
    "                    final_iter_trial.append(F_DNN.final_iter)\n",
    "                    accuracy_training_prcoess_trial.append(F_DNN.train_accuracy_list)\n",
    "                    accuracy_testing_prcoess_trial.append(F_DNN.test_accuracy_list)\n",
    "                    cost1_training_prcoess_trial.append(F_DNN.train_cost1_list)\n",
    "                    cost1_testing_prcoess_trial.append(F_DNN.test_cost1_list)\n",
    "                    cost2_training_prcoess_trial.append(F_DNN.train_cost2_list)\n",
    "                    cost2_testing_prcoess_trial.append(F_DNN.test_cost2_list)\n",
    "\n",
    "                    df.append([lam_list[e], i,con,F_DNN.h['M'], learning_rate, F_DNN.h['n_mini_batch'],F_DNN.best_iter,F_DNN.final_iter,\\\n",
    "                    F_DNN.accuracy_train, F_DNN.accuracy_test,\\\n",
    "                    train_FNR_gap,test_FNR_gap,train_FPR_gap,test_FPR_gap])\n",
    "\n",
    "\n",
    "                p_dic['train_accuracy'].append(accuracy_train_list)\n",
    "                p_dic['test_accuracy'].append(accuracy_test_list)\n",
    "                p_dic['train_cm0'].append(train_cm0_trial)\n",
    "                p_dic['train_cm1'].append(train_cm1_trial)\n",
    "                p_dic['test_cm0'].append(test_cm0_trial)\n",
    "                p_dic['test_cm1'].append(test_cm1_trial)\n",
    "                p_dic['train_FNR_gap'].append(train_FNR_gap_list)\n",
    "                p_dic['test_FNR_gap'].append(test_FNR_gap_list)\n",
    "                p_dic['train_FPR_gap'].append(train_FPR_gap_list)\n",
    "                p_dic['test_FPR_gap'].append(test_FPR_gap_list)\n",
    "\n",
    "                p_dic['TRAINING_PROCESS']['best_iter'].append(best_iter_trial)\n",
    "                p_dic['TRAINING_PROCESS']['final_iter'].append(final_iter_trial)\n",
    "                p_dic['TRAINING_PROCESS']['accuracy']['training_set'].append(accuracy_training_prcoess_trial)\n",
    "                p_dic['TRAINING_PROCESS']['accuracy']['testing_set'].append(accuracy_testing_prcoess_trial)\n",
    "                p_dic['TRAINING_PROCESS']['cost1']['training_set'].append(cost1_training_prcoess_trial)\n",
    "                p_dic['TRAINING_PROCESS']['cost1']['testing_set'].append(cost1_testing_prcoess_trial)\n",
    "                p_dic['TRAINING_PROCESS']['cost2']['training_set'].append(cost2_training_prcoess_trial)\n",
    "                p_dic['TRAINING_PROCESS']['cost2']['testing_set'].append(cost2_testing_prcoess_trial)\n",
    "\n",
    "                with open('results/' + folder+'/'+ datatype+'/'+ a[1]+'/'+run_name+'_lam'+str(lam_list[e])+'.pkl', 'wb') as f:\n",
    "                    pickle.dump(p_dic, f)\n",
    "\n",
    "\n",
    "            df = pd.DataFrame(df, columns = ['lambda','trial','fold','#layers','#lr','batch_size','best_iter','final_iter',\\\n",
    "                                             'accuracy_train','accuracy_test','FNR_gap_train','FNR_gap_test',\\\n",
    "                                            'FPR_gap_train','FPR_gap_test'])\n",
    "            df.to_csv('results/' + folder+'/'+ datatype+'/'+ a[1]+'/'+run_name+'_lam'+str(lam_list[e])+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder='Mode'\n",
    "if folder=='Mode':\n",
    "    data_varlist=['BUS_HIGH','BIKE_HIGH','CAR_HIGH','RIDESHARE_NEW']\n",
    "    name_corelist=['Bus','Bike','Car','Rideshare']\n",
    "\n",
    "    Z_var_list=['HH_RACE_MINORITY','FEMALE','POVERTY','MEDCOND_NEW', 'RURAL']\n",
    "    Z_note_list=['Race','Female','Poverty','Medcond','Rural']\n",
    "    \n",
    "else:\n",
    "    data_varlist=['PLACE','PRICE','2WRK_HOME_NEW','2WKRMHM_NEW']\n",
    "    name_corelist=['TB','GPI','WFH','WFHO']\n",
    "\n",
    "    Z_var_list=['HH_RACE_MINORITY','R_SEX_IMP_NEW','POVERTY','MEDCOND_NEW', 'URBRUR_NEW']\n",
    "    Z_note_list=['Race','Gender','Poverty','Medcond','Urban']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)\n",
    "\n",
    "\n",
    "method='cor_soft'\n",
    "datatype='Original'\n",
    "num_models = 3\n",
    "n_splits=5\n",
    "\n",
    "layer=3\n",
    "learning_rate=1e-4\n",
    "n_epoch=5000\n",
    "n_mini_batch=500000\n",
    "\n",
    "if layer==3:\n",
    "    model_path ='model_3lyr_'\n",
    "elif layer==0:\n",
    "    model_path ='model_base_'\n",
    "\n",
    "\n",
    "num_alt=2\n",
    "INCLUDE_VAL_SET = False\n",
    "INCLUDE_RAW_SET = False\n",
    "\n",
    "# DIR = 'results/' + folder+'/'+run_name + '/'\n",
    "num_training_samples = None\n",
    "\n",
    "\n",
    "lam_list=[0]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "    \n",
    "for k in zip(data_varlist,name_corelist):\n",
    "    run_name =model_path+k[1]#e.g.model_base_Bus\n",
    "    if folder=='Mode':\n",
    "        with open('data/NHTS_balanced/'+k[0]+'_2size_W.pkl', 'rb') as f:\n",
    "            input_data = pickle.load(f)\n",
    "    else:\n",
    "        with open('data/NHTS_unbalanced/NHTS_'+k[0]+'_W.pkl', 'rb') as f:\n",
    "            input_data = pickle.load(f)\n",
    "    X_all_raw=input_data['X_all_raw']\n",
    "    Y_all=input_data['Y_all']\n",
    "    \n",
    "    X_all_raw['FEMALE']=1-X_all_raw['R_SEX_IMP_NEW']\n",
    "    X_all_raw['RURAL']=1-X_all_raw['URBRUR_NEW']\n",
    "    \n",
    "    X_all_raw=X_all_raw.drop(['R_SEX_IMP_NEW','URBRUR_NEW'],axis=1)\n",
    "    \n",
    "    for a in zip(Z_var_list,Z_note_list):\n",
    "        Z_var=a[0]\n",
    "        DIR = 'results/' + folder+'/'+ datatype+'/'+ 'Race'+'/'+run_name+'/'\n",
    "        df = []\n",
    "        for e in range(len(lam_list)):\n",
    "            p_dic={}\n",
    "            p_dic['train_accuracy']=[]\n",
    "            p_dic['test_accuracy']=[]\n",
    "            p_dic['train_cm0']=[]\n",
    "            p_dic['train_cm1']=[]\n",
    "            p_dic['test_cm0']=[]\n",
    "            p_dic['test_cm1']=[]\n",
    "            p_dic['train_FNR_gap']=[]\n",
    "            p_dic['test_FNR_gap']=[]\n",
    "            p_dic['train_FPR_gap']=[]\n",
    "            p_dic['test_FPR_gap']=[]\n",
    "\n",
    "            p_dic['TRAINING_PROCESS']={}\n",
    "            p_dic['TRAINING_PROCESS']['best_iter']=[]\n",
    "            p_dic['TRAINING_PROCESS']['final_iter']=[]\n",
    "            p_dic['TRAINING_PROCESS']['accuracy']={}\n",
    "            p_dic['TRAINING_PROCESS']['cost1']={}\n",
    "            p_dic['TRAINING_PROCESS']['cost2']={}\n",
    "            p_dic['TRAINING_PROCESS']['accuracy']['training_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['accuracy']['testing_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost1']['training_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost1']['testing_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost2']['training_set']=[]\n",
    "            p_dic['TRAINING_PROCESS']['cost2']['testing_set']=[]\n",
    "                        \n",
    "            with open('results/' + folder+'/'+ datatype+'/'+ 'Race'+'/'+run_name+'.pkl', 'rb') as f:\n",
    "                p_dic_ref = pickle.load(f)\n",
    "\n",
    "            p_dic['TRAINING_PROCESS']=p_dic_ref['TRAINING_PROCESS']\n",
    "\n",
    "\n",
    "            for i in range(num_models):\n",
    "                kf = KFold(n_splits, shuffle=True,random_state=0)\n",
    "\n",
    "                #final results\n",
    "                accuracy_train_list = []\n",
    "                accuracy_test_list = []\n",
    "\n",
    "                train_cm0_trial=[]\n",
    "                train_cm1_trial=[]\n",
    "                test_cm0_trial=[]\n",
    "                test_cm1_trial=[]\n",
    "\n",
    "                train_FNR_gap_list=[]\n",
    "                test_FNR_gap_list=[]\n",
    "                train_FPR_gap_list=[]\n",
    "                test_FPR_gap_list=[]\n",
    "\n",
    "                #training process\n",
    "                best_iter_trial=[]\n",
    "                final_iter_trial=[]\n",
    "                accuracy_training_prcoess_trial=[]\n",
    "                accuracy_testing_prcoess_trial=[]\n",
    "                cost1_training_prcoess_trial=[]\n",
    "                cost1_testing_prcoess_trial=[]\n",
    "                cost2_training_prcoess_trial=[]\n",
    "                cost2_testing_prcoess_trial=[]\n",
    "\n",
    "                con=0\n",
    "                for train_idx, test_idx in kf.split(X_all_raw,Y_all):\n",
    "                    con+=1\n",
    "                    MODEL_NAME = 'lambda'+str(lam_list[e])+'_trial' + str(i)+'_fold'+str(con)\n",
    "\n",
    "                    X_train_raw = X_all_raw.iloc[train_idx,:]\n",
    "                    Y_train = Y_all[train_idx]\n",
    "\n",
    "                    X_test_raw = X_all_raw.iloc[test_idx,:]\n",
    "                    Y_test = Y_all[test_idx]\n",
    "                    \n",
    "                    X_train=X_train_raw.loc[:, X_train_raw.columns != 'WTPERFIN']\n",
    "                    X_test=X_test_raw.loc[:, X_test_raw.columns != 'WTPERFIN']\n",
    "                    W_train=X_train_raw['WTPERFIN']\n",
    "                    W_test=X_test_raw['WTPERFIN']\n",
    "                    \n",
    "                    \n",
    "                    N_bootstrap_sample = len(X_train_raw)\n",
    "                    F_DNN = FeedForward_DNN(num_alt,MODEL_NAME,INCLUDE_VAL_SET,INCLUDE_RAW_SET, DIR)\n",
    "                    \n",
    "                    F_DNN.load_data(Z_var)\n",
    "                    F_DNN.init_hyperparameter(lam_list[e],lr=learning_rate,lyr=layer,n_epoch=n_epoch,n_mini_batch=n_mini_batch) # could change the hyperparameter here by using F_DNN.change_hyperparameter(new)\n",
    "                    F_DNN.bootstrap_data(N_bootstrap_sample)\n",
    "                    F_DNN.build_model(method)\n",
    "                    F_DNN.evaluate_model()\n",
    "                     \n",
    "                    print(\" \")\n",
    "                    print('Y:',k[1],'; Z:',a[1],' ',MODEL_NAME,' completed')\n",
    "                    print('accuracy_train: ',F_DNN.accuracy_train,' ;accuracy_test: ',F_DNN.accuracy_test)\n",
    "\n",
    "\n",
    "                    #save results\n",
    "                    accuracy_train_list.append(F_DNN.accuracy_train)\n",
    "                    accuracy_test_list.append(F_DNN.accuracy_test)\n",
    "\n",
    "                    train_cm0=F_DNN.confusion_matrix_z0_train.ravel()\n",
    "                    train_cm1=F_DNN.confusion_matrix_z1_train.ravel()\n",
    "                    train_cm0_trial.append(train_cm0)\n",
    "                    train_cm1_trial.append(train_cm1)\n",
    "\n",
    "                    test_cm0=F_DNN.confusion_matrix_z0_test.ravel()\n",
    "                    test_cm1=F_DNN.confusion_matrix_z1_test.ravel()\n",
    "                    test_cm0_trial.append(test_cm0)\n",
    "                    test_cm1_trial.append(test_cm1)\n",
    "\n",
    "                    train_FNR0=train_cm0[2]/(train_cm0[2]+train_cm0[3])\n",
    "                    train_FNR1=train_cm1[2]/(train_cm1[2]+train_cm1[3])\n",
    "                    train_FNR_gap=train_FNR0-train_FNR1\n",
    "\n",
    "\n",
    "                    test_FNR0=test_cm0[2]/(test_cm0[2]+test_cm0[3])\n",
    "                    test_FNR1=test_cm1[2]/(test_cm1[2]+test_cm1[3])\n",
    "                    test_FNR_gap=test_FNR0-test_FNR1\n",
    "                    \n",
    "                    train_FPR0=train_cm0[1]/(train_cm0[0]+train_cm0[1])\n",
    "                    train_FPR1=train_cm1[1]/(train_cm1[0]+train_cm1[1])\n",
    "                    train_FPR_gap=train_FPR0-train_FPR1\n",
    "\n",
    "                    test_FPR0=test_cm0[1]/(test_cm0[0]+test_cm0[1])\n",
    "                    test_FPR1=test_cm1[1]/(test_cm1[0]+test_cm1[1])\n",
    "                    test_FPR_gap=test_FPR0-test_FPR1\n",
    "\n",
    "                    train_FNR_gap_list.append(train_FNR_gap)\n",
    "                    test_FNR_gap_list.append(test_FNR_gap)\n",
    "                    train_FPR_gap_list.append(train_FPR_gap)\n",
    "                    test_FPR_gap_list.append(test_FPR_gap)\n",
    "\n",
    "                    print('train_FNR_gap: ',train_FNR_gap,' ;test_FNR_gap: ',test_FNR_gap)\n",
    "                    print('train_FPR_gap: ',train_FPR_gap,' ;test_FPR_gap: ',test_FPR_gap)\n",
    "                    time_dur=round(time.time() - start_time, 3)\n",
    "                    print(\"--- %s seconds ---\" % round((time.time() - start_time),4))\n",
    "                    print(\" \")\n",
    "\n",
    "\n",
    "                    df.append([lam_list[e], i,con,F_DNN.h['M'], learning_rate, F_DNN.h['n_mini_batch'],\\\n",
    "                    F_DNN.accuracy_train, F_DNN.accuracy_test,\\\n",
    "                    train_FNR_gap,test_FNR_gap,train_FPR_gap,test_FPR_gap])\n",
    "\n",
    "\n",
    "                p_dic['train_accuracy'].append(accuracy_train_list)\n",
    "                p_dic['test_accuracy'].append(accuracy_test_list)\n",
    "                p_dic['train_cm0'].append(train_cm0_trial)\n",
    "                p_dic['train_cm1'].append(train_cm1_trial)\n",
    "                p_dic['test_cm0'].append(test_cm0_trial)\n",
    "                p_dic['test_cm1'].append(test_cm1_trial)\n",
    "                p_dic['train_FNR_gap'].append(train_FNR_gap_list)\n",
    "                p_dic['test_FNR_gap'].append(test_FNR_gap_list)\n",
    "                p_dic['train_FPR_gap'].append(train_FPR_gap_list)\n",
    "                p_dic['test_FPR_gap'].append(test_FPR_gap_list)\n",
    "\n",
    "            with open('results/' + folder+'/'+ datatype+'/'+ a[1]+'/'+run_name+'.pkl', 'wb') as f:\n",
    "                pickle.dump(p_dic, f)\n",
    "\n",
    "\n",
    "            df = pd.DataFrame(df, columns = ['lambda','trial','fold','#layers','#lr','batch_size',\\\n",
    "                                             'accuracy_train','accuracy_test','FNR_gap_train','FNR_gap_test','FPR_gap_train','FPR_gap_test'])\n",
    "            df.to_csv('results/' + folder+'/'+ datatype+'/'+ a[1]+'/'+run_name+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
